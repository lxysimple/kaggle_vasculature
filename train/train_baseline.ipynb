{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27a05a62",
   "metadata": {
    "papermill": {
     "duration": 0.004861,
     "end_time": "2023-12-27T10:19:07.821207",
     "exception": false,
     "start_time": "2023-12-27T10:19:07.816346",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**This code is base on [2.5d segmentaion baseline [training]](https://www.kaggle.com/code/tanakar/2-5d-segmentaion-baseline-training)**\n",
    "If you think my code is useful,please upvote it ^w^.\n",
    "* Version6:\n",
    "1. *     using kidney_1_dense for training and kidney_3_dense for val\n",
    "2. *     image_size = 512\n",
    "3. *     useing DiceLoss\n",
    "4. *     norm_with_clip\n",
    "5. *     fix some bug\n",
    "\n",
    "\n",
    "* This version is correspond with [2.5d Cutting model baseline [inference]](https://www.kaggle.com/code/yoyobar/2-5d-cutting-model-baseline-inference) version3\n",
    "\n",
    "\n",
    "\n",
    "According to my experiments, using kidney_1_dense for training and kidney_3_dense for val is the best. You can even get 0.757, but using 2d model(se_resnext50_32x4d), you can set CFG.in_chans=1 to make this notebook as a 2d model training notebook.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b06fe4",
   "metadata": {
    "papermill": {
     "duration": 0.003948,
     "end_time": "2023-12-27T10:19:07.829529",
     "exception": false,
     "start_time": "2023-12-27T10:19:07.825581",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4be6b1c3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-27T10:19:07.838717Z",
     "iopub.status.busy": "2023-12-27T10:19:07.838380Z",
     "iopub.status.idle": "2023-12-27T10:19:50.034933Z",
     "shell.execute_reply": "2023-12-27T10:19:50.032217Z"
    },
    "papermill": {
     "duration": 42.204328,
     "end_time": "2023-12-27T10:19:50.037862",
     "exception": false,
     "start_time": "2023-12-27T10:19:07.833534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/input/pip-download-for-segmentation-models-pytorch\r\n",
      "Processing /kaggle/input/pip-download-for-segmentation-models-pytorch/segmentation_models_pytorch-0.3.3-py3-none-any.whl\r\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.15.1)\r\n",
      "Processing /kaggle/input/pip-download-for-segmentation-models-pytorch/pretrainedmodels-0.7.4.tar.gz (from segmentation-models-pytorch)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hProcessing /kaggle/input/pip-download-for-segmentation-models-pytorch/efficientnet_pytorch-0.7.1.tar.gz (from segmentation-models-pytorch)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hProcessing /kaggle/input/pip-download-for-segmentation-models-pytorch/timm-0.9.2-py3-none-any.whl (from segmentation-models-pytorch)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (4.66.1)\r\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (10.1.0)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.0.0)\r\n",
      "Processing /kaggle/input/pip-download-for-segmentation-models-pytorch/munch-4.0.0-py2.py3-none-any.whl (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (6.0.1)\r\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.17.3)\r\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.4.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.24.3)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.31.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.12.2)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (4.5.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2023.10.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (21.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.2.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2023.7.22)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.0.9)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\r\n",
      "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\r\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=124596f0d5e88429989b89c5f05503fe79636c24936421203d3ee84a5ae42037\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/d2/e7/71/a031831a75a14914d29e2f255fcbc113d825ff4762d42f0315\r\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60943 sha256=be0e772f6a4c2fb40aa46148c921ec793eed1512f60624c0ee20f14699d7e0a3\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/10/53/cc/d9cbdaa15d821ad4845e69994708dcad78fcddf4c92a753bdf\r\n",
      "Successfully built efficientnet-pytorch pretrainedmodels\r\n",
      "Installing collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\r\n",
      "  Attempting uninstall: timm\r\n",
      "    Found existing installation: timm 0.9.10\r\n",
      "    Uninstalling timm-0.9.10:\r\n",
      "      Successfully uninstalled timm-0.9.10\r\n",
      "Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.3 timm-0.9.2\r\n"
     ]
    }
   ],
   "source": [
    "# 创建目录以存放预训练模型的缓存文件\n",
    "!mkdir -p /root/.cache/torch/hub/checkpoints/\n",
    "\n",
    "# 将预训练模型的权重文件复制到缓存目录\n",
    "!cp /kaggle/input/se-net-pretrained-imagenet-weights/* /root/.cache/torch/hub/checkpoints/\n",
    "\n",
    "# 导入所需的库\n",
    "import torch as tc\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os, sys, cv2\n",
    "from torch.cuda.amp import autocast\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "\n",
    "# 安装并导入分割模型库\n",
    "!python -m pip install --no-index --find-links=/kaggle/input/pip-download-for-segmentation-models-pytorch segmentation-models-pytorch\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# 导入 Albumentations 的 PyTorch 转换模块\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# 导入 PyTorch 数据集和数据加载工具\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 导入 PyTorch 的 DataParallel 模块\n",
    "from torch.nn.parallel import DataParallel # 单机多卡的分布式训练（数据并行） 模型训练加速\n",
    "\n",
    "# 导入文件和路径处理工具\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f977254f",
   "metadata": {
    "papermill": {
     "duration": 0.009293,
     "end_time": "2023-12-27T10:19:50.058087",
     "exception": false,
     "start_time": "2023-12-27T10:19:50.048794",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1506b3d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T10:19:50.077540Z",
     "iopub.status.busy": "2023-12-27T10:19:50.076731Z",
     "iopub.status.idle": "2023-12-27T10:19:50.088587Z",
     "shell.execute_reply": "2023-12-27T10:19:50.087673Z"
    },
    "papermill": {
     "duration": 0.023809,
     "end_time": "2023-12-27T10:19:50.090861",
     "exception": false,
     "start_time": "2023-12-27T10:19:50.067052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 显存： 骨干网络的复杂度 vs 输入尺寸 vs 批大小\n",
    "# 【理想情况】：模型输入1024 * 1024，1500 * 1500\n",
    "\n",
    "# 前20 epoch 512 * 512  训练模型\n",
    "# 后20 epoch 1024 * 1024 继续训练\n",
    "\n",
    "class CFG:\n",
    "    # ============== 预测目标 =============\n",
    "    target_size = 1\n",
    "\n",
    "    # ============== 模型配置 =============\n",
    "    model_name = 'Unet'\n",
    "    backbone = 'se_resnext50_32x4d'\n",
    "\n",
    "    in_chans = 5  # 输入通道数\n",
    "    # ============== 训练配置 =============\n",
    "    image_size = 512  # 图片大小\n",
    "    input_size = 512  # 输入尺寸\n",
    "\n",
    "    train_batch_size = 16  # 训练批量大小\n",
    "    valid_batch_size = train_batch_size * 2  # 验证批量大小\n",
    "\n",
    "    epochs = 20  # 训练轮数\n",
    "    lr = 6e-5  # 学习率\n",
    "    chopping_percentile = 1e-3  # 切割百分比\n",
    "    # ============== 折数 =============\n",
    "    valid_id = 1  # 验证集编号\n",
    "\n",
    "    # ============== 数据增强 =============\n",
    "    train_aug_list = [\n",
    "        A.Rotate(limit=45, p=0.5),  # 旋转\n",
    "        A.RandomScale(scale_limit=(0.8, 1.25), interpolation=cv2.INTER_CUBIC, p=0.5),  # 随机缩放\n",
    "        A.RandomCrop(input_size, input_size, p=1),  # 随机裁剪\n",
    "        A.RandomGamma(p=0.75),  # 随机Gamma变换\n",
    "        A.RandomBrightnessContrast(p=0.5, ),  # 随机亮度对比度变换\n",
    "        A.GaussianBlur(p=0.5),  # 高斯模糊\n",
    "        A.MotionBlur(p=0.5),  # 运动模糊\n",
    "        A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),  # 网格扭曲\n",
    "        ToTensorV2(transpose_mask=True),  # 转换为张量\n",
    "    ]\n",
    "    train_aug = A.Compose(train_aug_list)\n",
    "    valid_aug_list = [\n",
    "        ToTensorV2(transpose_mask=True),  # 转换为张量\n",
    "    ]\n",
    "    valid_aug = A.Compose(valid_aug_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f93f18",
   "metadata": {
    "papermill": {
     "duration": 0.006267,
     "end_time": "2023-12-27T10:19:50.103388",
     "exception": false,
     "start_time": "2023-12-27T10:19:50.097121",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b51c1f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T10:19:50.117131Z",
     "iopub.status.busy": "2023-12-27T10:19:50.116851Z",
     "iopub.status.idle": "2023-12-27T10:19:50.124058Z",
     "shell.execute_reply": "2023-12-27T10:19:50.123300Z"
    },
    "papermill": {
     "duration": 0.016349,
     "end_time": "2023-12-27T10:19:50.125876",
     "exception": false,
     "start_time": "2023-12-27T10:19:50.109527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, CFG, weight=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 初始化模型，使用了 segmentation_models_pytorch 库中的 Unet 模型\n",
    "        self.model = smp.Unet(\n",
    "            encoder_name=CFG.backbone, \n",
    "            encoder_weights=weight,\n",
    "            in_channels=CFG.in_chans,\n",
    "            classes=CFG.target_size,\n",
    "            activation=None,\n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        # 模型的前向传播\n",
    "        output = self.model(image)\n",
    "        # 如果需要，可以在这里对输出进行额外的处理\n",
    "        # output = output.squeeze(-1)\n",
    "        return output[:, 0]  # 选择输出的第一个通道，这里假设输出是多通道的sigmoid()\n",
    "\n",
    "def build_model(weight=\"imagenet\"):\n",
    "    # 加载环境变量\n",
    "    load_dotenv()\n",
    "\n",
    "    # 输出模型名称和使用的骨干网络\n",
    "    print('model_name', CFG.model_name)\n",
    "    print('backbone', CFG.backbone)\n",
    "\n",
    "    # 构建并返回模型\n",
    "    model = CustomModel(CFG, weight)\n",
    "    return model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2e9c89",
   "metadata": {
    "papermill": {
     "duration": 0.006497,
     "end_time": "2023-12-27T10:19:50.138459",
     "exception": false,
     "start_time": "2023-12-27T10:19:50.131962",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffb40f4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T10:19:50.152394Z",
     "iopub.status.busy": "2023-12-27T10:19:50.152132Z",
     "iopub.status.idle": "2023-12-27T10:19:50.185297Z",
     "shell.execute_reply": "2023-12-27T10:19:50.184610Z"
    },
    "papermill": {
     "duration": 0.04223,
     "end_time": "2023-12-27T10:19:50.187124",
     "exception": false,
     "start_time": "2023-12-27T10:19:50.144894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def min_max_normalization(x: tc.Tensor) -> tc.Tensor:\n",
    "    \"\"\"最小-最大归一化函数\n",
    "\n",
    "    参数:\n",
    "    x (tc.Tensor): 输入张量，形状为(batch, f1, ...)\n",
    "\n",
    "    返回:\n",
    "    tc.Tensor: 归一化后的张量，保持原始形状\n",
    "    \"\"\"\n",
    "    # 获取输入张量的形状\n",
    "    shape = x.shape\n",
    "\n",
    "    # 如果输入张量的维度大于2，将其展平成二维张量\n",
    "    if x.ndim > 2:\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "    # 计算每行的最小值和最大值\n",
    "    min_ = x.min(dim=-1, keepdim=True)[0]\n",
    "    max_ = x.max(dim=-1, keepdim=True)[0]\n",
    "\n",
    "    # 如果最小值的平均值为0，最大值的平均值为1，说明已经是归一化状态，直接返回\n",
    "    if min_.mean() == 0 and max_.mean() == 1:\n",
    "        return x.reshape(shape)\n",
    "\n",
    "    # 进行最小-最大归一化处理\n",
    "    x = (x - min_) / (max_ - min_ + 1e-9)\n",
    "    return x.reshape(shape)\n",
    "\n",
    "def norm_with_clip(x: tc.Tensor, smooth=1e-5):\n",
    "    \"\"\"带截断的标准化函数\n",
    "\n",
    "    参数:\n",
    "    x (tc.Tensor): 输入张量\n",
    "    smooth (float): 平滑值，用于避免除零错误，默认为1e-5\n",
    "\n",
    "    返回:\n",
    "    tc.Tensor: 标准化后的张量\n",
    "    \"\"\"\n",
    "    # 获取除第一维外的所有维度\n",
    "    dim = list(range(1, x.ndim))\n",
    "    \n",
    "    # 计算均值和标准差\n",
    "    mean = x.mean(dim=dim, keepdim=True)\n",
    "    std = x.std(dim=dim, keepdim=True)\n",
    "\n",
    "    # 标准化处理\n",
    "    x = (x - mean) / (std + smooth)\n",
    "\n",
    "    # 对大于5和小于-3的值进行截断处理\n",
    "    x[x > 5] = (x[x > 5] - 5) * 1e-3 + 5\n",
    "    x[x < -3] = (x[x < -3] + 3) * 1e-3 - 3\n",
    "\n",
    "    return x\n",
    "\n",
    "def add_noise(x: tc.Tensor, max_randn_rate=0.1, randn_rate=None, x_already_normed=False):\n",
    "    \"\"\"\n",
    "    给定输入张量 x，添加噪声并返回处理后的张量\n",
    "\n",
    "    参数:\n",
    "        - x: 输入张量，形状为 (batch, f1, f2, ...)\n",
    "        - max_randn_rate: 随机噪声的最大比例，默认为 0.1\n",
    "        - randn_rate: 可选参数，手动指定噪声比例，如果为 None 则随机生成\n",
    "        - x_already_normed: 布尔值，指示输入张量是否已经进行了标准化\n",
    "\n",
    "    返回:\n",
    "        处理后的张量，其方差已被归一化\n",
    "\n",
    "    注意:\n",
    "        - 如果输入张量已经标准化 (x_already_normed=True)，则 x_std 为全 1 张量，x_mean 为全 0 张量。\n",
    "        - 如果输入张量未标准化，根据输入的维度进行标准化处理。\n",
    "\n",
    "    参考:\n",
    "        - https://blog.csdn.net/chaosir1991/article/details/106960408\n",
    "    \"\"\"\n",
    "    ndim = x.ndim - 1\n",
    "\n",
    "    if x_already_normed:\n",
    "        x_std = tc.ones([x.shape[0]] + [1] * ndim, device=x.device, dtype=x.dtype)\n",
    "        x_mean = tc.zeros([x.shape[0]] + [1] * ndim, device=x.device, dtype=x.dtype)\n",
    "    else:\n",
    "        dim = list(range(1, x.ndim))\n",
    "        x_std = x.std(dim=dim, keepdim=True)\n",
    "        x_mean = x.mean(dim=dim, keepdim=True)\n",
    "\n",
    "    if randn_rate is None:\n",
    "        randn_rate = max_randn_rate * np.random.rand() * tc.rand(x_mean.shape, device=x.device, dtype=x.dtype)\n",
    "\n",
    "    # 计算噪声缩放系数\n",
    "    cache = (x_std ** 2 + (x_std * randn_rate) ** 2) ** 0.5 + 1e-7\n",
    "\n",
    "    # 添加噪声并返回处理后的张量\n",
    "    return (x - x_mean + tc.randn(size=x.shape, device=x.device, dtype=x.dtype) * randn_rate * x_std) / cache\n",
    "\n",
    "class Data_loader(Dataset):\n",
    "    def __init__(self, paths, is_label):\n",
    "        # 初始化函数，接收数据集路径和是否为标签的参数\n",
    "        self.paths = paths  # 数据集路径列表\n",
    "        self.paths.sort()   # 对路径进行排序\n",
    "        self.is_label = is_label  # 是否为标签数据\n",
    "    \n",
    "    def __len__(self):\n",
    "        # 返回数据集的长度\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # 获取数据集中指定索引的样本\n",
    "        img = cv2.imread(self.paths[index], cv2.IMREAD_GRAYSCALE)  # 读取灰度图像\n",
    "        img = tc.from_numpy(img)  # 将图像转换为PyTorch张量\n",
    "\n",
    "        if self.is_label:\n",
    "            # 如果是标签数据，将非零像素值设为255（二值化）\n",
    "            img = (img != 0).to(tc.uint8) * 255\n",
    "        else:\n",
    "            # 如果不是标签数据，将图像转换为8位无符号整数类型\n",
    "            img = img.to(tc.uint8)\n",
    "\n",
    "        return img  # 返回处理后的图像\n",
    "\n",
    "def load_data(paths, is_label=False):\n",
    "    # 创建Data_loader对象，处理数据路径和是否为标签的标志\n",
    "    data_loader = Data_loader(paths, is_label)\n",
    "    # 创建DataLoader，设置批量大小为16，使用2个工作进程加载数据\n",
    "    data_loader = DataLoader(data_loader, batch_size=16, num_workers=2)\n",
    "    # 存储数据的列表\n",
    "    data = []\n",
    "    # 遍历数据加载器，将每个批次的数据添加到列表中\n",
    "    for x in tqdm(data_loader):\n",
    "        data.append(x)\n",
    "    \n",
    "    # 将数据列表拼接为一个张量\n",
    "    x = tc.cat(data, dim=0)\n",
    "    # 释放内存，删除数据列表\n",
    "    del data\n",
    "    \n",
    "    # 如果不是标签数据\n",
    "    if not is_label:\n",
    "        # 对数据进行百分比截断处理\n",
    "        ########################################################################\n",
    "        # 计算数据张量的阈值\n",
    "        TH = x.reshape(-1).numpy()\n",
    "        # 根据设定的百分比确定阈值位置\n",
    "        index = -int(len(TH) * CFG.chopping_percentile)\n",
    "        # 对阈值进行分区操作，并取得分区后的阈值\n",
    "        TH: int = np.partition(TH, index)[index]\n",
    "        # 将大于阈值的元素设置为阈值\n",
    "        x[x > TH] = int(TH)\n",
    "        ########################################################################\n",
    "        # 重新计算数据张量的阈值\n",
    "        TH = x.reshape(-1).numpy()\n",
    "        # 根据设定的百分比确定阈值位置\n",
    "        index = -int(len(TH) * CFG.chopping_percentile)\n",
    "        # 对阈值进行分区操作，并取得分区后的阈值\n",
    "        TH: int = np.partition(TH, -index)[-index]\n",
    "        # 将小于阈值的元素设置为阈值\n",
    "        x[x < TH] = int(TH)\n",
    "        ########################################################################\n",
    "        # 对数据进行最小-最大归一化，并将数据类型转换为uint8\n",
    "        x = (min_max_normalization(x.to(tc.float16)[None])[0] * 255).to(tc.uint8)\n",
    "    \n",
    "    # 返回处理后的数据张量\n",
    "    return x\n",
    "\n",
    "#https://www.kaggle.com/code/kashiwaba/sennet-hoa-train-unet-simple-baseline\n",
    "def dice_coef(y_pred: tc.Tensor, y_true: tc.Tensor, thr=0.5, dim=(-1, -2), epsilon=0.001):\n",
    "    # 对预测值进行sigmoid激活，将其转换到0到1的范围\n",
    "    y_pred = y_pred.sigmoid()\n",
    "    \n",
    "    # 将真实值转换为float32类型\n",
    "    y_true = y_true.to(tc.float32)\n",
    "    \n",
    "    # 将预测值二值化，使用阈值thr，默认为0.5\n",
    "    y_pred = (y_pred > thr).to(tc.float32)\n",
    "    \n",
    "    # 计算交集（intersection），即预测值和真实值同时为1的位置之和\n",
    "    inter = (y_true * y_pred).sum(dim=dim)\n",
    "    \n",
    "    # 计算分母，即真实值和预测值中1的位置之和\n",
    "    den = y_true.sum(dim=dim) + y_pred.sum(dim=dim)\n",
    "    \n",
    "    # 计算Dice系数，加入平滑项epsilon以防分母为0\n",
    "    dice = ((2 * inter + epsilon) / (den + epsilon)).mean()\n",
    "    \n",
    "    # 返回Dice系数作为评估指标\n",
    "    return dice\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        # 如果你的模型包含 sigmoid 或等效的激活层，请注释掉下面这行\n",
    "        inputs = inputs.sigmoid()   \n",
    "        \n",
    "        # 将标签和预测张量展平\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        # 计算交集\n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        \n",
    "        # 计算 Dice 系数\n",
    "        dice = (2. * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        # 返回 Dice 损失\n",
    "        return 1 - dice\n",
    "\n",
    "class Kaggld_Dataset(Dataset):\n",
    "    def __init__(self, x: list, y: list, arg: bool = False):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.x = x  # 输入图像列表，每个元素为形状为(C, H, W)的图像\n",
    "        self.y = y  # 目标图像列表，每个元素为形状为(C, H, W)的图像\n",
    "        self.image_size = CFG.image_size  # 图像大小\n",
    "        self.in_chans = CFG.in_chans  # 输入通道数\n",
    "        self.arg = arg  # 是否进行数据增强\n",
    "        if arg:\n",
    "            self.transform = CFG.train_aug  # 训练数据增强配置\n",
    "        else:\n",
    "            self.transform = CFG.valid_aug  # 验证数据增强配置\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return sum([y.shape[0] - self.in_chans for y in self.y])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        i = 0\n",
    "        for x in self.x:\n",
    "            if index > x.shape[0] - self.in_chans:\n",
    "                index -= x.shape[0] - self.in_chans\n",
    "                i += 1\n",
    "            else:\n",
    "                break\n",
    "        x = self.x[i]\n",
    "        y = self.y[i]\n",
    "\n",
    "        x_index = np.random.randint(0, x.shape[1] - self.image_size)\n",
    "        y_index = np.random.randint(0, x.shape[2] - self.image_size)\n",
    "\n",
    "        x = x[index:index + self.in_chans, x_index:x_index + self.image_size, y_index:y_index + self.image_size]\n",
    "        y = y[index + self.in_chans // 2, x_index:x_index + self.image_size, y_index:y_index + self.image_size]\n",
    "\n",
    "        # 进行数据增强\n",
    "        data = self.transform(image=x.numpy().transpose(1, 2, 0), mask=y.numpy())\n",
    "        x = data['image']\n",
    "        y = data['mask'] >= 127\n",
    "\n",
    "        if self.arg:\n",
    "            i = np.random.randint(4)\n",
    "            x = x.rot90(i, dims=(1, 2))\n",
    "            y = y.rot90(i, dims=(0, 1))\n",
    "            for i in range(3):\n",
    "                if np.random.randint(2):\n",
    "                    x = x.flip(dims=(i,))\n",
    "                    if i >= 1:\n",
    "                        y = y.flip(dims=(i - 1,))\n",
    "        return x, y  # 返回处理后的图像数据，类型为(uint8, uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d0836e",
   "metadata": {
    "papermill": {
     "duration": 0.005999,
     "end_time": "2023-12-27T10:19:50.199210",
     "exception": false,
     "start_time": "2023-12-27T10:19:50.193211",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cc760db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T10:19:50.212308Z",
     "iopub.status.busy": "2023-12-27T10:19:50.212067Z",
     "iopub.status.idle": "2023-12-27T10:23:21.514064Z",
     "shell.execute_reply": "2023-12-27T10:23:21.512707Z"
    },
    "papermill": {
     "duration": 211.311188,
     "end_time": "2023-12-27T10:23:21.516454",
     "exception": false,
     "start_time": "2023-12-27T10:19:50.205266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 143/143 [00:42<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2279, 1303, 912])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 143/143 [00:26<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2279, 1303, 912])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:24<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([501, 1706, 1510])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:09<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([501, 1706, 1510])\n"
     ]
    }
   ],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "# 数据集根路径\n",
    "root_path = \"/kaggle/input/blood-vessel-segmentation/\"\n",
    "# 数据集中子路径\n",
    "paths = [\"/kaggle/input/blood-vessel-segmentation/train/kidney_1_dense\"]\n",
    "\n",
    "# 遍历子路径\n",
    "for i, path in enumerate(paths):\n",
    "    # 排除特定路径\n",
    "    if path == \"/kaggle/input/blood-vessel-segmentation/train/kidney_3_dense\":\n",
    "        continue\n",
    "    \n",
    "    # 加载图像数据（非标签）\n",
    "    x = load_data(glob(f\"{path}/images/*\"), is_label=False)\n",
    "    print(x.shape)\n",
    "    \n",
    "    # 加载标签数据\n",
    "    y = load_data(glob(f\"{path}/labels/*\"), is_label=True)\n",
    "    print(y.shape)\n",
    "    \n",
    "    # 将数据添加到训练集\n",
    "    train_x.append(x)\n",
    "    train_y.append(y)\n",
    "\n",
    "    # 数据维度变换及数据增强\n",
    "    #(C,H,W)\n",
    "    #augmentation\n",
    "    train_x.append(x.permute(1, 2, 0))\n",
    "    train_y.append(y.permute(1, 2, 0))\n",
    "    train_x.append(x.permute(2, 0, 1))\n",
    "    train_y.append(y.permute(2, 0, 1))\n",
    "\n",
    "# 验证集路径\n",
    "path1 = \"/kaggle/input/blood-vessel-segmentation/train/kidney_3_sparse\"\n",
    "path2 = \"/kaggle/input/blood-vessel-segmentation/train/kidney_3_dense\"\n",
    "# 获取验证集图像和标签路径列表\n",
    "paths_y = glob(f\"{path2}/labels/*\")\n",
    "paths_x = [x.replace(\"labels\", \"images\").replace(\"dense\", \"sparse\") for x in paths_y]\n",
    "\n",
    "# 加载验证集图像和标签数据\n",
    "val_x = load_data(paths_x, is_label=False)\n",
    "print(val_x.shape)\n",
    "val_y = load_data(paths_y, is_label=True)\n",
    "print(val_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ad9450",
   "metadata": {
    "papermill": {
     "duration": 0.023923,
     "end_time": "2023-12-27T10:23:21.565537",
     "exception": false,
     "start_time": "2023-12-27T10:23:21.541614",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "845fdbb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T10:23:21.619274Z",
     "iopub.status.busy": "2023-12-27T10:23:21.618917Z",
     "iopub.status.idle": "2023-12-27T11:12:33.682094Z",
     "shell.execute_reply": "2023-12-27T11:12:33.681077Z"
    },
    "papermill": {
     "duration": 2952.093396,
     "end_time": "2023-12-27T11:12:33.684642",
     "exception": false,
     "start_time": "2023-12-27T10:23:21.591246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name Unet\n",
      "backbone se_resnext50_32x4d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:0,loss:0.9553,score:0.0606,lr2.9121e-05: 100%|██████████| 280/280 [02:45<00:00,  1.69it/s]\n",
      "val-->loss:0.9760,score:0.0645: 100%|██████████| 16/16 [00:11<00:00,  1.42it/s]\n",
      "epoch:1,loss:0.8552,score:0.3642,lr5.9700e-05: 100%|██████████| 280/280 [02:20<00:00,  1.99it/s]\n",
      "val-->loss:0.8855,score:0.6277: 100%|██████████| 16/16 [00:05<00:00,  3.15it/s]\n",
      "epoch:2,loss:0.5504,score:0.6757,lr5.9662e-05: 100%|██████████| 280/280 [02:20<00:00,  1.99it/s]\n",
      "val-->loss:0.6437,score:0.7231: 100%|██████████| 16/16 [00:04<00:00,  3.31it/s]\n",
      "epoch:3,loss:0.2961,score:0.7438,lr5.8511e-05: 100%|██████████| 280/280 [02:21<00:00,  1.98it/s]\n",
      "val-->loss:0.4823,score:0.7451: 100%|██████████| 16/16 [00:04<00:00,  3.33it/s]\n",
      "epoch:4,loss:0.2078,score:0.7542,lr5.6573e-05: 100%|██████████| 280/280 [02:19<00:00,  2.01it/s]\n",
      "val-->loss:0.4183,score:0.7489: 100%|██████████| 16/16 [00:05<00:00,  3.13it/s]\n",
      "epoch:5,loss:0.1742,score:0.7692,lr5.3903e-05: 100%|██████████| 280/280 [02:18<00:00,  2.01it/s]\n",
      "val-->loss:0.3448,score:0.7725: 100%|██████████| 16/16 [00:04<00:00,  3.31it/s]\n",
      "epoch:6,loss:0.1602,score:0.7694,lr5.0574e-05: 100%|██████████| 280/280 [02:20<00:00,  2.00it/s]\n",
      "val-->loss:0.3345,score:0.7480: 100%|██████████| 16/16 [00:04<00:00,  3.26it/s]\n",
      "epoch:7,loss:0.1495,score:0.7677,lr4.6678e-05: 100%|██████████| 280/280 [02:21<00:00,  1.98it/s]\n",
      "val-->loss:0.3120,score:0.7660: 100%|██████████| 16/16 [00:04<00:00,  3.30it/s]\n",
      "epoch:8,loss:0.1398,score:0.7721,lr4.2322e-05: 100%|██████████| 280/280 [02:20<00:00,  1.99it/s]\n",
      "val-->loss:0.2983,score:0.7825: 100%|██████████| 16/16 [00:04<00:00,  3.26it/s]\n",
      "epoch:9,loss:0.1293,score:0.7797,lr3.7627e-05: 100%|██████████| 280/280 [02:20<00:00,  1.99it/s]\n",
      "val-->loss:0.2889,score:0.7686: 100%|██████████| 16/16 [00:04<00:00,  3.30it/s]\n",
      "epoch:10,loss:0.1291,score:0.7774,lr3.2721e-05: 100%|██████████| 280/280 [02:21<00:00,  1.98it/s]\n",
      "val-->loss:0.2925,score:0.7893: 100%|██████████| 16/16 [00:04<00:00,  3.26it/s]\n",
      "epoch:11,loss:0.1248,score:0.7831,lr2.7740e-05: 100%|██████████| 280/280 [02:20<00:00,  1.99it/s]\n",
      "val-->loss:0.2659,score:0.7726: 100%|██████████| 16/16 [00:05<00:00,  3.11it/s]\n",
      "epoch:12,loss:0.1205,score:0.7890,lr2.2822e-05: 100%|██████████| 280/280 [02:21<00:00,  1.98it/s]\n",
      "val-->loss:0.2707,score:0.7715: 100%|██████████| 16/16 [00:05<00:00,  3.08it/s]\n",
      "epoch:13,loss:0.1207,score:0.7862,lr1.8101e-05: 100%|██████████| 280/280 [02:19<00:00,  2.00it/s]\n",
      "val-->loss:0.2947,score:0.7611: 100%|██████████| 16/16 [00:04<00:00,  3.24it/s]\n",
      "epoch:14,loss:0.1185,score:0.7897,lr1.3709e-05: 100%|██████████| 280/280 [02:20<00:00,  1.99it/s]\n",
      "val-->loss:0.2866,score:0.7573: 100%|██████████| 16/16 [00:04<00:00,  3.25it/s]\n",
      "epoch:15,loss:0.1181,score:0.7861,lr9.7653e-06: 100%|██████████| 280/280 [02:20<00:00,  1.99it/s]\n",
      "val-->loss:0.2766,score:0.7677: 100%|██████████| 16/16 [00:04<00:00,  3.22it/s]\n",
      "epoch:16,loss:0.1126,score:0.7931,lr6.3796e-06: 100%|██████████| 280/280 [02:21<00:00,  1.98it/s]\n",
      "val-->loss:0.2728,score:0.7898: 100%|██████████| 16/16 [00:04<00:00,  3.23it/s]\n",
      "epoch:17,loss:0.1147,score:0.7829,lr3.6451e-06: 100%|██████████| 280/280 [02:21<00:00,  1.98it/s]\n",
      "val-->loss:0.2824,score:0.7776: 100%|██████████| 16/16 [00:04<00:00,  3.28it/s]\n",
      "epoch:18,loss:0.1137,score:0.7918,lr1.6370e-06: 100%|██████████| 280/280 [02:23<00:00,  1.95it/s]\n",
      "val-->loss:0.2777,score:0.7891: 100%|██████████| 16/16 [00:05<00:00,  3.17it/s]\n",
      "epoch:19,loss:0.1156,score:0.7934,lr4.1079e-07: 100%|██████████| 280/280 [02:21<00:00,  1.98it/s]\n",
      "val-->loss:0.2528,score:0.7947: 100%|██████████| 16/16 [00:04<00:00,  3.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# 启用cudnn加速，并进行基准测试\n",
    "tc.backends.cudnn.enabled = True\n",
    "tc.backends.cudnn.benchmark = True\n",
    "    \n",
    "# 创建训练数据集对象，使用Kaggld_Dataset类，传入训练数据和标签，arg=True表示进行一些额外的操作\n",
    "train_dataset = Kaggld_Dataset(train_x, train_y, arg=True)\n",
    "# 创建训练数据加载器，设置批大小、工作线程数、是否打乱数据、是否将数据存储在固定内存中\n",
    "train_dataset = DataLoader(train_dataset, batch_size=CFG.train_batch_size, num_workers=2, shuffle=True, pin_memory=True)\n",
    "\n",
    "# 创建验证数据集对象，使用Kaggld_Dataset类，传入验证数据和标签\n",
    "val_dataset = Kaggld_Dataset([val_x], [val_y])\n",
    "# 创建验证数据加载器，设置批大小、工作线程数、是否打乱数据、是否将数据存储在固定内存中\n",
    "val_dataset = DataLoader(val_dataset, batch_size=CFG.valid_batch_size, num_workers=2, shuffle=False, pin_memory=True)\n",
    "\n",
    "# 构建模型\n",
    "model = build_model()\n",
    "# 使用DataParallel进行模型并行处理\n",
    "model = DataParallel(model)\n",
    "\n",
    "# 使用DiceLoss作为损失函数\n",
    "loss_fc = DiceLoss()\n",
    "# 使用AdamW优化器，传入模型参数和学习率\n",
    "optimizer = tc.optim.AdamW(model.parameters(), lr=CFG.lr)\n",
    "\n",
    "# 使用GradScaler进行梯度缩放，用于混合精度训练 2080 3090 / 1080ti\n",
    "scaler = tc.cuda.amp.GradScaler()\n",
    "\n",
    "# 设置学习率调度器，使用OneCycleLR策略\n",
    "scheduler = tc.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=CFG.lr,\n",
    "                                              steps_per_epoch=len(train_dataset), epochs=CFG.epochs+1,\n",
    "                                              pct_start=0.1)\n",
    "\n",
    "# 循环训练模型\n",
    "for epoch in range(CFG.epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # 创建进度条以显示训练进度\n",
    "    time = tqdm(range(len(train_dataset)))\n",
    "    losss = 0\n",
    "    scores = 0\n",
    "    \n",
    "    # 遍历训练数据集\n",
    "    for i, (x, y) in enumerate(train_dataset):\n",
    "        x = x.cuda().to(tc.float32)\n",
    "        y = y.cuda().to(tc.float32)\n",
    "        \n",
    "        # 数据预处理\n",
    "        x = norm_with_clip(x.reshape(-1, *x.shape[2:])).reshape(x.shape)\n",
    "        x = add_noise(x, max_randn_rate=0.5, x_already_normed=True)\n",
    "        \n",
    "        # 使用自动混合精度进行前向传播和损失计算\n",
    "        with autocast():\n",
    "            pred = model(x)\n",
    "            loss = loss_fc(pred, y)\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # 计算并更新平均损失和分数\n",
    "        score = dice_coef(pred.detach(), y)\n",
    "        losss = (losss * i + loss.item()) / (i + 1)\n",
    "        scores = (scores * i + score) / (i + 1)\n",
    "        \n",
    "        # 更新进度条\n",
    "        time.set_description(f\"epoch:{epoch},loss:{losss:.4f},score:{scores:.4f},lr{optimizer.param_groups[0]['lr']:.4e}\")\n",
    "        time.update()\n",
    "        \n",
    "        # 释放内存\n",
    "        del loss, pred\n",
    "    \n",
    "    # 关闭进度条\n",
    "    time.close()\n",
    "    \n",
    "    # 模型评估阶段\n",
    "    model.eval()\n",
    "    \n",
    "    # 创建进度条以显示验证进度\n",
    "    time = tqdm(range(len(val_dataset)))\n",
    "    val_losss = 0\n",
    "    val_scores = 0\n",
    "    \n",
    "    # 遍历验证数据集\n",
    "    for i, (x, y) in enumerate(val_dataset):\n",
    "        x = x.cuda().to(tc.float32)\n",
    "        y = y.cuda().to(tc.float32)\n",
    "        \n",
    "        # 数据预处理\n",
    "        x = norm_with_clip(x.reshape(-1, *x.shape[2:])).reshape(x.shape)\n",
    "        \n",
    "        # 使用自动混合精度进行前向传播和损失计算，但不进行梯度计算\n",
    "        with autocast():\n",
    "            with tc.no_grad():\n",
    "                pred = model(x)\n",
    "                loss = loss_fc(pred, y)\n",
    "        \n",
    "        # 计算并更新平均损失和分数\n",
    "        score = dice_coef(pred.detach(), y)\n",
    "        val_losss = (val_losss * i + loss.item()) / (i + 1)\n",
    "        val_scores = (val_scores * i + score) / (i + 1)\n",
    "        \n",
    "        # 更新进度条\n",
    "        time.set_description(f\"val-->loss:{val_losss:.4f},score:{val_scores:.4f}\")\n",
    "        time.update()\n",
    "\n",
    "    # 关闭进度条\n",
    "    time.close()\n",
    "\n",
    "# 保存模型参数\n",
    "tc.save(model.module.state_dict(), f\"./{CFG.backbone}_{epoch}_loss{losss:.2f}_score{scores:.2f}_val_loss{val_losss:.2f}_val_score{val_scores:.2f}.pt\")\n",
    "\n",
    "# 关闭最后一个进度条\n",
    "time.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cabf8ed-2c65-4252-bf67-f1c5503455bd",
   "metadata": {
    "papermill": {
     "duration": 1.007909,
     "end_time": "2023-12-27T11:12:35.787600",
     "exception": false,
     "start_time": "2023-12-27T11:12:34.779691",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1、【在现有代码的基础上】：512尺寸 训练 扩展到 1024尺寸\n",
    "2、增加【现有的数据集】：受限内存\n",
    "3、测试集阈值进行搜索，建议在验证集上来确定阈值。\n",
    "\n",
    "4、\n",
    "    Resnet50 * 3 1024尺寸 模型 提交 0.850\n",
    "    Efficient B2 * 3 1024尺寸 模型 提交 0.852"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 6962461,
     "sourceId": 61446,
     "sourceType": "competition"
    },
    {
     "datasetId": 1074109,
     "sourceId": 1807973,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 150248402,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3.6 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3216.319545,
   "end_time": "2023-12-27T11:12:40.468088",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-27T10:19:04.148543",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
